
import avians.util.image as aui
import avians.nn.common as anc
from datetime import datetime as dt

import argparse
import cv2
import numpy as np

import keras.objectives as ko

import logging
LOG = logging.getLogger(__name__)

def text_detection_v2(image,
                      autoencoder,
                      ac_input_size=64,
                      loss_threshold=0.5):
    # filter very small elements, smaller than 5 pixel
    components, bounding_box_arr = aui.image_segmentation(image, min_area=5, max_area=0.9)

    LOG.debug("=== components.shape ===")
    LOG.debug(components.shape)
    LOG.debug("=== bounding_box_arr ===")
    LOG.debug(bounding_box_arr.shape)
    LOG.debug("=== np.min(bounding_box_arr[\"area\"]) ===")
    LOG.debug(np.min(bounding_box_arr["area"]))
    resized_components = aui.resize_components(components,
                                               bounding_box_arr,
                                               sizex=ac_input_size,
                                               sizey=ac_input_size)

    LOG.debug("=== resized_components.shape ===")
    LOG.debug(resized_components.shape)
    n_components, n_x, n_y = resized_components.shape
    resized_components.resize((n_components, 1, n_x, n_y))
    LOG.debug("=== resized_components.shape (after resize) ===")
    LOG.debug(resized_components.shape)
    predictions = autoencoder.predict(resized_components)
    LOG.debug("=== predictions ===")
    LOG.debug(predictions)
    dissimilarities = np.array([(np.abs(resized_components[i] - predictions[i])).mean() for i in range(n_components)])
    # dissimilarities = np.array([ko.binary_crossentropy(resized_components, predictions) for i in range(n_components)])
    LOG.debug("=== dissimilarities ===")
    LOG.debug(dissimilarities)
    text_components = components[dissimilarities <= loss_threshold]
    LOG.debug("=== text_components.shape ===")
    LOG.debug(text_components.shape)
    text_image = aui.merge_image_array(text_components)
    return text_image * 255

def load_autoencoder(fn):
    m = anc.load_keras_model(fn,
                             loss="binary_crossentropy",
                             optimizer="adadelta")
    m.summary()
    return m

def main_caller(autoencoder,
                image,
                output): 
    
    img = cv2.imread(image)
    autoencoder = load_autoencoder(autoencoder)
    result = text_detection_v2(img, autoencoder)
    cv2.imwrite(output, result)
    print("Result Saved To: {}".format(output))
    assert False

def main(): 
    parser = argparse.ArgumentParser(description="""
    Detects textual regions on the given image using the supplied model generated by train_rnn
    """,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument('autoencoder', help="Keras model name to detect text (without .json or .h5 extension)")
    parser.add_argument('image', help="Image that we are going to detect the text")
    parser.add_argument('--output', help="File to save the image", 
                        default="text-detection-result-{}.png".format(dt.now().strftime("%F-%T")))

    args = vars(parser.parse_args())
    print(args)
    main_caller(**args)

if __name__ == '__main__': 
    main()
